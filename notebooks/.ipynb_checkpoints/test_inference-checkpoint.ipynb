{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer\n",
    "import tensorflow as tf\n",
    "from transformers import TFAutoModel\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 128\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def set_seed(SEED):\n",
    "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_token( phrase):\n",
    "    tokens = tokenizer.encode_plus(phrase,\n",
    "                                   max_length = seq_len,\n",
    "                                   truncation=True,\n",
    "                                   padding='max_length',\n",
    "                                   add_special_tokens=True,\n",
    "                                   return_tensors='tf', return_token_type_ids=False )\n",
    "    \n",
    "    return {'input_ids':tf.cast(tokens['input_ids'], tf.float64), 'attention_mask':tf.cast(tokens['attention_mask'], tf.float64)}\n",
    "\n",
    "def get_prediction(my_model, data):\n",
    "    _predicted_probs = []\n",
    "    for item in tqdm(data['sentence']):\n",
    "        ret = ret_token(item.lower())\n",
    "        probs = my_model.predict(ret)\n",
    "        _predicted_probs.append(probs)\n",
    "    return _predicted_probs\n",
    "\n",
    "def get_full_data_preds(my_model, data):\n",
    "    _preds = get_prediction(my_model, data)\n",
    "    _preds = [item[0] for item in _preds]\n",
    "    _preds_df = pd.DataFrame(_preds)\n",
    "    return pd.concat([data, _preds_df], axis=1)\n",
    "    \n",
    "def execute_inference(data, valid_fold):\n",
    "    my_model = tf.keras.models.load_model('../checkpoints/fold_'+str(valid_fold)+'/best_model.h5')\n",
    "    _preds= get_full_data_preds(my_model, data)\n",
    "    os.makedirs('../results/fold_'+str(valid_fold), exist_ok=True)\n",
    "    \n",
    "    _preds.to_csv('../results/fold_'+str(valid_fold)+'/test_preds.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../data/raw/sofmattress_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There are only 2 models</td>\n",
       "      <td>NO_NODES_DETECTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Single</td>\n",
       "      <td>NO_NODES_DETECTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What's difference between ergo and ortho</td>\n",
       "      <td>COMPARISON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Return order</td>\n",
       "      <td>RETURN_EXCHANGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hai not recieved my product</td>\n",
       "      <td>DELAY_IN_DELIVERY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   sentence              label\n",
       "0                   There are only 2 models  NO_NODES_DETECTED\n",
       "1                                    Single  NO_NODES_DETECTED\n",
       "2  What's difference between ergo and ortho         COMPARISON\n",
       "3                              Return order    RETURN_EXCHANGE\n",
       "4               Hai not recieved my product  DELAY_IN_DELIVERY"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 397/397 [00:27<00:00, 14.30it/s]\n",
      "100%|██████████| 397/397 [00:27<00:00, 14.36it/s]\n",
      "100%|██████████| 397/397 [00:27<00:00, 14.48it/s]\n",
      "100%|██████████| 397/397 [00:27<00:00, 14.38it/s]\n",
      "100%|██████████| 397/397 [00:27<00:00, 14.34it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,5):\n",
    "    execute_inference(df_test,i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../config/labels.json') as json_file:\n",
    "    label_mapping = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for i in range(0,5):\n",
    "    local_df = pd.read_csv('../results/fold_'+ str(i) +'/test_preds.csv')\n",
    "    df =pd.concat([df, local_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "\n",
    "df_mean = df.groupby('index').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>There are only 2 models</td>\n",
       "      <td>NO_NODES_DETECTED</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.003039</td>\n",
       "      <td>0.001263</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>0.001940</td>\n",
       "      <td>0.945710</td>\n",
       "      <td>0.035868</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.003437</td>\n",
       "      <td>0.000725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Single</td>\n",
       "      <td>NO_NODES_DETECTED</td>\n",
       "      <td>0.011035</td>\n",
       "      <td>0.006604</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.006642</td>\n",
       "      <td>0.000893</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000693</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>0.007013</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>0.119074</td>\n",
       "      <td>0.008688</td>\n",
       "      <td>0.004157</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>0.819387</td>\n",
       "      <td>0.001122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>What's difference between ergo and ortho</td>\n",
       "      <td>COMPARISON</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.001262</td>\n",
       "      <td>0.993293</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.001308</td>\n",
       "      <td>0.001283</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000637</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Return order</td>\n",
       "      <td>RETURN_EXCHANGE</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.009688</td>\n",
       "      <td>0.003035</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.002209</td>\n",
       "      <td>0.001804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.031462</td>\n",
       "      <td>0.134524</td>\n",
       "      <td>0.795190</td>\n",
       "      <td>0.009349</td>\n",
       "      <td>0.002357</td>\n",
       "      <td>0.000187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Hai not recieved my product</td>\n",
       "      <td>DELAY_IN_DELIVERY</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.007549</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.002177</td>\n",
       "      <td>0.001184</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.067952</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>0.910713</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.003484</td>\n",
       "      <td>0.000104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                  sentence              label  \\\n",
       "0      0                   There are only 2 models  NO_NODES_DETECTED   \n",
       "1      1                                    Single  NO_NODES_DETECTED   \n",
       "2      2  What's difference between ergo and ortho         COMPARISON   \n",
       "3      3                              Return order    RETURN_EXCHANGE   \n",
       "4      4               Hai not recieved my product  DELAY_IN_DELIVERY   \n",
       "\n",
       "          0         1         2         3         4         5         6  ...  \\\n",
       "0  0.000375  0.000068  0.000338  0.000329  0.003039  0.001263  0.000326  ...   \n",
       "1  0.011035  0.006604  0.000569  0.000412  0.000286  0.006642  0.000893  ...   \n",
       "2  0.000013  0.000054  0.000104  0.001262  0.993293  0.000183  0.000355  ...   \n",
       "3  0.000443  0.009688  0.003035  0.000981  0.000256  0.002209  0.001804  ...   \n",
       "4  0.000139  0.007549  0.000729  0.000635  0.000200  0.002177  0.001184  ...   \n",
       "\n",
       "         11        12        13        14        15        16        17  \\\n",
       "0  0.001333  0.001940  0.945710  0.035868  0.000174  0.000614  0.000439   \n",
       "1  0.000693  0.000338  0.007013  0.000730  0.119074  0.008688  0.004157   \n",
       "2  0.000019  0.000152  0.001308  0.001283  0.000061  0.000032  0.000637   \n",
       "3  0.000139  0.000036  0.000279  0.000049  0.031462  0.134524  0.795190   \n",
       "4  0.000015  0.000010  0.000215  0.000037  0.067952  0.001047  0.910713   \n",
       "\n",
       "         18        19        20  \n",
       "0  0.000309  0.003437  0.000725  \n",
       "1  0.000510  0.819387  0.001122  \n",
       "2  0.000096  0.000068  0.000085  \n",
       "3  0.009349  0.002357  0.000187  \n",
       "4  0.000852  0.003484  0.000104  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df_fold=pd.read_csv('../results/fold_1/test_preds.csv')\n",
    "_df_fold = _df_fold[['sentence','label']].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_test = pd.concat([_df_fold, df_mean], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_test.label = final_df_test.label.map(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cols = [str(i) for i in range(0,21)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predicted_label(row):\n",
    "    local_row = row[pred_cols]\n",
    "    indx = np.argmax(local_row)\n",
    "    conf = local_row[indx]\n",
    "    row['confidence'] = conf\n",
    "    row['pred_label'] = indx\n",
    "    return row\n",
    "\n",
    "final_df_test['pred_label'] = -1\n",
    "final_df_test['confidence'] = -1\n",
    "\n",
    "\n",
    "final_df_test = final_df_test.apply(get_predicted_label, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_testing_accuracy(row):\n",
    "    if row['label'] == row['pred_label']:\n",
    "        return 'yes'\n",
    "    else:\n",
    "        return 'no'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_test['correct'] = final_df_test.apply(get_testing_accuracy, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     0.561713\n",
       "yes    0.438287\n",
       "Name: correct, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df_test['correct'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inscope Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "yes    75.324675\n",
       "no     24.675325\n",
       "Name: correct, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df_test[final_df_test['label']!=21].correct.value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.753275866374932"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "f1_score(final_df_test[final_df_test['label']!=21]['label'], final_df_test[final_df_test['label']!=21]['pred_label'],  average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inscope Accuracy is 75%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################\n",
      "Threshold:  0.1\n",
      "##############################\n",
      "Threshold:  0.2\n",
      "##############################\n",
      "Threshold:  0.3\n",
      "##############################\n",
      "Threshold:  0.4\n",
      "##############################\n",
      "Threshold:  0.5\n",
      "##############################\n",
      "Threshold:  0.6\n",
      "##############################\n",
      "Threshold:  0.7\n",
      "##############################\n",
      "Threshold:  0.8\n",
      "##############################\n",
      "Threshold:  0.9\n"
     ]
    }
   ],
   "source": [
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "accuracy = []\n",
    "inscope_accuracy = []\n",
    "f1 = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    print(\"#\"*30)\n",
    "    print(\"Threshold: \", threshold)\n",
    "    local_df = final_df_test.copy()\n",
    "    local_df.loc[local_df['confidence'] < threshold, 'pred_label'] = 21\n",
    "    local_df['correct'] = local_df.apply(get_testing_accuracy, axis=1)\n",
    "   \n",
    "    \n",
    "    correct = len(local_df[local_df['correct'] == 'yes'])\n",
    "    incorrect = len(local_df[local_df['correct'] == 'no'])\n",
    "    \n",
    "    acc = correct / (correct + incorrect) * 100\n",
    "    \n",
    "    local_df = local_df[local_df['label']!=21]\n",
    "    \n",
    "    correct = len(local_df[local_df['correct'] == 'yes'])\n",
    "    incorrect = len(local_df[local_df['correct'] == 'no'])\n",
    "#     print(local_df['label'].unique())\n",
    "#     print(local_df['pred_label'].unique())\n",
    "#     print((local_df['label'].nunique()))\n",
    "#     print((local_df['pred_label'].nunique()))\n",
    "    \n",
    "#     for i in local_df['label'].unique():\n",
    "#         if i not in local_df['pred_label'].unique():\n",
    "#             print(i)\n",
    "            \n",
    "    f1.append(f1_score(list(local_df['label']), list(local_df['pred_label']),  average='weighted'))\n",
    "    \n",
    "    in_acc = correct / (correct + incorrect) * 100\n",
    "    accuracy.append(acc)\n",
    "    inscope_accuracy.append(in_acc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Inscope Accuracy</th>\n",
       "      <th>F1 Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>43.828715</td>\n",
       "      <td>75.324675</td>\n",
       "      <td>0.753276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>47.103275</td>\n",
       "      <td>75.324675</td>\n",
       "      <td>0.755909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>57.430730</td>\n",
       "      <td>70.995671</td>\n",
       "      <td>0.731247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>63.979849</td>\n",
       "      <td>67.099567</td>\n",
       "      <td>0.709103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>67.758186</td>\n",
       "      <td>64.502165</td>\n",
       "      <td>0.694730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6</td>\n",
       "      <td>69.269521</td>\n",
       "      <td>58.874459</td>\n",
       "      <td>0.667155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7</td>\n",
       "      <td>67.254408</td>\n",
       "      <td>50.216450</td>\n",
       "      <td>0.590784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8</td>\n",
       "      <td>62.720403</td>\n",
       "      <td>39.393939</td>\n",
       "      <td>0.484181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9</td>\n",
       "      <td>59.193955</td>\n",
       "      <td>32.034632</td>\n",
       "      <td>0.401859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Threshold   Accuracy  Inscope Accuracy  F1 Scores\n",
       "0        0.1  43.828715         75.324675   0.753276\n",
       "1        0.2  47.103275         75.324675   0.755909\n",
       "2        0.3  57.430730         70.995671   0.731247\n",
       "3        0.4  63.979849         67.099567   0.709103\n",
       "4        0.5  67.758186         64.502165   0.694730\n",
       "5        0.6  69.269521         58.874459   0.667155\n",
       "6        0.7  67.254408         50.216450   0.590784\n",
       "7        0.8  62.720403         39.393939   0.484181\n",
       "8        0.9  59.193955         32.034632   0.401859"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'Threshold': thresholds, 'Accuracy':accuracy, 'Inscope Accuracy':inscope_accuracy, 'F1 Scores':f1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
